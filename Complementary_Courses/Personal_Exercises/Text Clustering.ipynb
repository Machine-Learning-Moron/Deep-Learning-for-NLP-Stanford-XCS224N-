{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from os.path import join as JP\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils.nlp_utils import preproces\n",
    "from utils.general import parse_yaml, ensure_directories\n",
    "\n",
    "from scripts.catalog import (\n",
    "    Catalog, Document, Corpus,\n",
    "    load_catalog, load_corpus)\n",
    "\n",
    "config = parse_yaml('config.yaml')\n",
    "paths = config['paths']\n",
    "ensure_directories(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog(path=paths['catalog'],name='spacy_pipeline_on_US_corpus')\n",
    "# catalog.documents[0].sp_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus into Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[OK] Corpus loaded into Catalog'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = load_corpus(path=paths['catalog'], name='only_en_countries')\n",
    "catalog.load_corpus(corpus=corpus)\n",
    "# catalog.save(path=paths['catalog'],name='test1_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter down the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog recuded from 15 to 15\n"
     ]
    }
   ],
   "source": [
    "OF_INTEREST = ['US'] # ['CA','AU']\n",
    "filters = dict(\n",
    "    topic = ['isocyanate'],\n",
    "    country = OF_INTEREST,\n",
    "    raw_text_len = 5000)\n",
    "\n",
    "sub_catalog = catalog.filter_catalog(filters)\n",
    "sub_catalog.documents = sub_catalog.documents[:15]\n",
    "print('Catalog recuded from {} to {}'.format(\n",
    "    len(catalog.documents), len(sub_catalog.documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT CATALOG INTO THE TWO CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive documents:  15\n",
      "Negative documents:  0\n"
     ]
    }
   ],
   "source": [
    "filters = dict(label='relevant')\n",
    "pos_catalog = sub_catalog.filter_catalog(filters)\n",
    "\n",
    "filters = dict(label='irrelevant')\n",
    "neg_catalog = sub_catalog.filter_catalog(filters)\n",
    "\n",
    "print('Positive documents: ',len(pos_catalog.documents))\n",
    "print('Negative documents: ',len(neg_catalog.documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working for the Positive Labels since this is only for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pos_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Application published. OKAZOE, Takashi;Nagasaki, Y'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = catalog.documents[0]\n",
    "document.clean_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_cleaning(\n",
    "    document,\n",
    "    tags_to_keep=['JJ', 'NN', 'NNS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "    entities_to_remove=['ORG,NORP,GPE,PERSON']):\n",
    "\n",
    "    def pass_test(w, tags=tags_to_keep):\n",
    "        if w.ent_type_ == 0:\n",
    "                return w.tag_ in tags and not w.is_punct and not w.is_stop and w.ent_ not in entities_to_remove\n",
    "        return w.tag_ in tags and not w.is_punct and not w.is_stop \n",
    "\n",
    "    words = [ word for word in document if pass_test(word)]\n",
    "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in words ]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply intense cleaning and save Catalog instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Parsing doc  0\n",
      "[INFO]: Parsing doc  1\n",
      "[INFO]: Parsing doc  2\n",
      "[INFO]: Parsing doc  3\n",
      "[INFO]: Parsing doc  4\n",
      "[INFO]: Parsing doc  5\n",
      "[INFO]: Parsing doc  6\n",
      "[INFO]: Parsing doc  7\n",
      "[INFO]: Parsing doc  8\n",
      "[INFO]: Parsing doc  9\n",
      "[INFO]: Parsing doc  10\n",
      "[INFO]: Parsing doc  11\n",
      "[INFO]: Parsing doc  12\n",
      "[INFO]: Parsing doc  13\n",
      "[INFO]: Parsing doc  14\n"
     ]
    }
   ],
   "source": [
    "for d,doc in enumerate(catalog.documents):\n",
    "    print('[INFO]: Parsing doc ',d)\n",
    "    catalog.documents[d].processed_text = spacy_cleaning(nlp(doc.clean_text))\n",
    "catalog.save(path=paths['catalog'],name='spacy_pipeline_on_US_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application publish asahi glas method produce carb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.documents[0].processed_text[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the Corpus for Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application publish asahi glas method produce carbamate compound carbamate compound method produce isocyanate compound present invention relate method produce carbamate compound comprise react fluorine contain carbonic diester compound represent formula aromatic diamine compound represent formula catalyst produce carbamate compound represent formula method produce isocyanate compound represent formula carbamate compound catalyst represent fluorine contain represent divalent divalent divalent aro'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = catalog.collect_corpus(attr='processed_text', form=list)\n",
    "document = corpus[0]\n",
    "document[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 3000 # TODO: Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=.1,\n",
    "    max_df=.7,\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    max_features=EMBED_SIZE,\n",
    "    ngram_range=(1,3),\n",
    "    lowercase=True,\n",
    "    stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absence</th>\n",
       "      <th>absence catalyst</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolute pressure</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>accompany</th>\n",
       "      <th>accord claim</th>\n",
       "      <th>accord claim compound</th>\n",
       "      <th>accord compound</th>\n",
       "      <th>...</th>\n",
       "      <th>weight step production</th>\n",
       "      <th>weight weight</th>\n",
       "      <th>wt</th>\n",
       "      <th>yield base</th>\n",
       "      <th>yield base addition</th>\n",
       "      <th>yield base example</th>\n",
       "      <th>yield base hexamethylene</th>\n",
       "      <th>yield carbamic</th>\n",
       "      <th>yield carbamic acid</th>\n",
       "      <th>zinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017735</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able   absence  absence catalyst  absolute  absolute pressure  \\\n",
       "0  0.000000  0.147455          0.147455  0.000000           0.000000   \n",
       "1  0.000000  0.000000          0.000000  0.030103           0.003763   \n",
       "2  0.003873  0.004278          0.002852  0.000000           0.000000   \n",
       "3  0.000000  0.000000          0.000000  0.000000           0.000000   \n",
       "4  0.000000  0.000000          0.000000  0.000000           0.000000   \n",
       "\n",
       "   accelerate  accompany  accord claim  accord claim compound  \\\n",
       "0    0.009941   0.000000      0.000000                    0.0   \n",
       "1    0.000000   0.017735      0.010343                    0.0   \n",
       "2    0.001538   0.000840      0.000000                    0.0   \n",
       "3    0.000000   0.000000      0.000000                    0.0   \n",
       "4    0.000000   0.000000      0.000000                    0.0   \n",
       "\n",
       "   accord compound  ...  weight step production  weight weight        wt  \\\n",
       "0         0.000000  ...                0.000000       0.000000  0.000000   \n",
       "1         0.000000  ...                0.000000       0.000000  0.041129   \n",
       "2         0.001273  ...                0.003327       0.001538  0.000649   \n",
       "3         0.000000  ...                0.000000       0.000000  0.000000   \n",
       "4         0.000000  ...                0.000000       0.000000  0.000000   \n",
       "\n",
       "   yield base  yield base addition  yield base example  \\\n",
       "0    0.024851             0.000000            0.000000   \n",
       "1    0.000000             0.000000            0.000000   \n",
       "2    0.010766             0.004753            0.002852   \n",
       "3    0.000000             0.000000            0.000000   \n",
       "4    0.000000             0.000000            0.000000   \n",
       "\n",
       "   yield base hexamethylene  yield carbamic  yield carbamic acid      zinc  \n",
       "0                  0.000000        0.000000             0.000000  0.004551  \n",
       "1                  0.000000        0.000000             0.000000  0.000000  \n",
       "2                  0.004278        0.001901             0.001901  0.000352  \n",
       "3                  0.000000        0.000000             0.000000  0.000000  \n",
       "4                  0.000000        0.000000             0.000000  0.000000  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pos_catalog.to_matrix(\n",
    "    vectorizer=vectorizer,\n",
    "    modelname='TFIDF',\n",
    "    max_docs=None)\n",
    "print(tfidf.representation.shape)\n",
    "tfidf.representation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_to_dataframe(model): # Model\n",
    "    return pd.DataFrame({\n",
    "        \"word\": [ k for k,v in model.token2id.items() ],\n",
    "        \"idf\":  [ model.mapping.idf_[v] \\\n",
    "                    for k,v in model.token2id.items()]\n",
    "        }).sort_values(\"idf\",ascending=False)\n",
    "\n",
    "def get_most_relevant_terms(\n",
    "    tfidf_df:pd.DataFrame,\n",
    "    n_terms:int):\n",
    "    ''' Return the first max_terms terms relevant by their IDF value '''\n",
    "    if not isinstance(tfidf_df,pd.DataFrame):\n",
    "        tfidf_df = tfidf_to_dataframe(tfidf_df)\n",
    "    return tfidf_df.sort_values(\n",
    "        by='idf', ascending=False).iloc[:n_terms,:]['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>contain carbon</td>\n",
       "      <td>2.673976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>inside thin</td>\n",
       "      <td>2.673976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>portion return</td>\n",
       "      <td>2.673976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>diisocyanate extract</td>\n",
       "      <td>2.673976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>addition solution</td>\n",
       "      <td>2.673976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      word       idf\n",
       "1500        contain carbon  2.673976\n",
       "1914           inside thin  2.673976\n",
       "1931        portion return  2.673976\n",
       "1929  diisocyanate extract  2.673976\n",
       "1928     addition solution  2.673976"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_scores = tfidf_to_dataframe(tfidf)\n",
    "idf_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contain carbon',\n",
       " 'carbonate carbonate carbonate',\n",
       " 'example reaction apparatus',\n",
       " 'method present embodiment',\n",
       " 'acid ester unsubstitute',\n",
       " 'ester unsubstitute carbamic',\n",
       " 'group example group',\n",
       " 'carbon atom substitute',\n",
       " 'primary amine represent',\n",
       " 'stirrer place flask']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = get_most_relevant_terms(idf_scores,n_terms=50)\n",
    "terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_clustering(\n",
    "    model, #:Model\n",
    "    num_clusters:int=4, \n",
    "    words_per_cluster:int=None):\n",
    "    '''\n",
    "    TODO: Consider MiniBatchKMeans\n",
    "    \n",
    "    Clusters using k-mean with k words per cluster\n",
    "    ----------------------------------------------\n",
    "        The k-words are the k closest to the centroid of that cluster\n",
    "        Equivalently: the words are the ones most present in the 'fake'\n",
    "        document represented by the centroid of the cluster\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "        - model: Trained instance of class Model\n",
    "        - num_clusters: Number of Clusters to look for\n",
    "        - words_per_cluster: K parameter above\n",
    "\n",
    "    Returns:\n",
    "    -------- \n",
    "        - Dict key='cluster id', value=k_words_closest_to_centroid\n",
    "    '''\n",
    "    # 1. Performs K-Means algorithm to identify clusters\n",
    "    km = KMeans(\n",
    "        n_clusters=num_clusters,\n",
    "        n_jobs=-1)\n",
    "    km.fit_transform(model.representation)\n",
    "    # clusters = km.labels_.tolist()\n",
    "\n",
    "    # Bring K most similar words to centroid\n",
    "    closests_words_to_centroids = km.cluster_centers_.argsort()[:, :-words_per_cluster:-1] \n",
    "    \n",
    "    cluster_words = defaultdict(list)\n",
    "    for i in range(num_clusters):\n",
    "        for idx in closests_words_to_centroids[i, :words_per_cluster]:\n",
    "            cluster_words[i].append(model.id2token[idx])\n",
    "    return cluster_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3000)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=4)\n",
    "clusters = km.fit(tfidf.representation)\n",
    "clusters.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 3, 1, 0, 2, 2, 3, 2, 0, 2, 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = clusters.predict(tfidf.representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1816, 1905,  691, 2625],\n",
       "       [1574, 1483,  435,  275],\n",
       "       [2098, 2964, 1751, 2088],\n",
       "       [ 192, 2513, 2872, 2687]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closests_words_to_centroids = km.cluster_centers_.argsort()[:, :-5:-1] \n",
    "closests_words_to_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_words = defaultdict(list)\n",
    "for i in range(4):\n",
    "    for idx in closests_words_to_centroids[i, :5]:\n",
    "        cluster_words[i].append(tfidf.id2token[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['mixer', 'nozzle', 'conduit', 'static'],\n",
       "             1: ['isomer', 'include isomer', 'carbamic', 'atom'],\n",
       "             2: ['polyisocyanate', 'weight', 'membrane', 'polyamide'],\n",
       "             3: ['aniline', 'second', 'tube', 'stream']})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the importance of each word within the cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only looking IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfidf\n",
    "scores = defaultdict(list)\n",
    "\n",
    "'''\n",
    "scores = dict(\n",
    "    words = defaultdict(list),\n",
    "    idf = defaultdict(list),\n",
    "    maxtf_idf = defaultdict(list),\n",
    "    avg_tf_idf = defaultdict(list),\n",
    "    norm_tf_idf = defaultdict(list))\n",
    "'''\n",
    "\n",
    "def tf_idf_of_word(model,k,v):\n",
    "    return model.representation[[k]].values, model.mapping.idf_[v]\n",
    "    \n",
    "for k,v in model.token2id.items():\n",
    "    scores['words'].append(k)\n",
    "    t,i = tf_idf_of_word(model,k,v)\n",
    "    scores['idf'].append(i)\n",
    "    scores['max_tf_idf'].append(np.max(t)*i)\n",
    "    scores['avg_tf_idf'].append(np.max(t)*i)\n",
    "    scores['norm_tf_idf'].append(np.linalg.norm(t)*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>idf</th>\n",
       "      <th>max_tf_idf</th>\n",
       "      <th>avg_tf_idf</th>\n",
       "      <th>norm_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carbamate</td>\n",
       "      <td>1.826679</td>\n",
       "      <td>0.540593</td>\n",
       "      <td>0.540593</td>\n",
       "      <td>0.868281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fluorine</td>\n",
       "      <td>2.673976</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.854370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carbonic</td>\n",
       "      <td>2.163151</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>0.296121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>represent</td>\n",
       "      <td>1.470004</td>\n",
       "      <td>0.357015</td>\n",
       "      <td>0.357015</td>\n",
       "      <td>0.452279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>formula</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.220037</td>\n",
       "      <td>0.220037</td>\n",
       "      <td>0.356585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words       idf  max_tf_idf  avg_tf_idf  norm_tf_idf\n",
       "0  carbamate  1.826679    0.540593    0.540593     0.868281\n",
       "1   fluorine  2.673976    0.854299    0.854299     0.854370\n",
       "2   carbonic  2.163151    0.272016    0.272016     0.296121\n",
       "3  represent  1.470004    0.357015    0.357015     0.452279\n",
       "4    formula  1.693147    0.220037    0.220037     0.356585"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_to_idf_dict(model):\n",
    "    # lambda maxtf_idf: tf,idf = max(tf)*idf\n",
    "    return {\n",
    "        \"word\": [ k for k,v in model.token2id.items() ],\n",
    "        \"idf\":  [ model.mapping.idf_[v] for k,v in model.token2id.items()]}\n",
    "\n",
    "\n",
    "def tfidf_to_idf_scores(model): # Model\n",
    "    d = tfidf_to_idf_dict(model)\n",
    "    return pd.DataFrame().sort_values(\"idf\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C0: mixer:2.6739764335716716\n",
      "C0: nozzle:2.386294361119891\n",
      "C0: conduit:2.386294361119891\n",
      "C0: static:2.386294361119891\n",
      "C1: isomer:1.3746934494414107\n",
      "C1: include isomer:2.6739764335716716\n",
      "C1: carbamic:2.163150809805681\n",
      "C1: atom:1.3746934494414107\n",
      "C2: polyisocyanate:1.3746934494414107\n",
      "C2: weight:1.3746934494414107\n",
      "C2: membrane:2.163150809805681\n",
      "C2: polyamide:2.6739764335716716\n",
      "C3: aniline:1.826678573184468\n",
      "C3: second:1.3746934494414107\n",
      "C3: tube:1.5753641449035618\n",
      "C3: stream:1.826678573184468\n"
     ]
    }
   ],
   "source": [
    "idf_lookup = dict(tfidf_to_dataframe(tfidf).values)\n",
    "for c,words in cluster_words.items():\n",
    "    for word in words:\n",
    "        print('C{}: {}:{}'.format(c,word,idf_lookup[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUBSAMBPLE BY CLSUTERS!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
