{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EMBED_SIZE = 5    # word_size\n",
    "SENTECE_LEN = 6   # input_size\n",
    "HIDDEN_SIZE = 10  # hidden_size\n",
    "sentence = torch.randn(1, SENTECE_LEN, EMBED_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1944, -0.3090, -1.8691,  0.7323, -0.0364],\n",
       "        [ 0.5767, -1.1036, -1.5389,  1.5197,  0.7917],\n",
       "        [ 1.1138,  0.0613, -0.9815,  0.6418, -0.4962],\n",
       "        [ 0.5006, -0.7771,  1.1670, -0.4962, -2.1714],\n",
       "        [-0.6125,  1.8546,  1.1128,  0.2832, -1.2968],\n",
       "        [ 0.2312,  0.7097,  1.3771,  0.0922, -0.6707]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 words, each a 5-dim vector\n"
     ]
    }
   ],
   "source": [
    "print('There are {} words, each a {}-dim vector'.format(*sentence[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTM Cell\n",
    "\n",
    "Args:\n",
    "    - input_size: The number of expected features in the input `x`\n",
    "    - hidden_size: The number of features in the hidden state `h`\n",
    "    - bias: If ``False``, then the layer does not use bias weights `b_ih` and\n",
    "        `b_hh`. Default: ``True``\n",
    "\n",
    "Inputs: input, (h_0, c_0)\n",
    "    - **input** of shape `(batch, input_size)`: tensor containing input features\n",
    "    - **h_0** of shape `(batch, hidden_size)`: tensor containing the initial hidden\n",
    "      state for each element in the batch.\n",
    "    - **c_0** of shape `(batch, hidden_size)`: tensor containing the initial cell state\n",
    "      for each element in the batch.\n",
    "\n",
    "      If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n",
    "\n",
    "Outputs: (h_1, c_1)\n",
    "    - **h_1** of shape `(batch, hidden_size)`: tensor containing the next hidden state\n",
    "      for each element in the batch\n",
    "    - **c_1** of shape `(batch, hidden_size)`: tensor containing the next cell state\n",
    "      for each element in the batch\n",
    "\n",
    "Attributes:\n",
    "    - weight_ih: the learnable input-hidden weights, of shape\n",
    "        `(4*hidden_size, input_size)`\n",
    "    - weight_hh: the learnable hidden-hidden weights, of shape\n",
    "        `(4*hidden_size, hidden_size)`\n",
    "    - bias_ih: the learnable input-hidden bias, of shape `(4*hidden_size)`\n",
    "    - bias_hh: the learnable hidden-hidden bias, of shape `(4*hidden_size)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.LSTMCell(input_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = torch.randn(BATCH_SIZE, HIDDEN_SIZE)\n",
    "cx = torch.randn(BATCH_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input batch size 6 doesn't match hidden[0] batch size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-b379e6db2340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSENTECE_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         return _VF.lstm_cell(\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_hidden\u001b[0;34m(self, input, hx, hidden_label)\u001b[0m\n\u001b[1;32m    767\u001b[0m             raise RuntimeError(\n\u001b[1;32m    768\u001b[0m                 \"Input batch size {} doesn't match hidden{} batch size {}\".format(\n\u001b[0;32m--> 769\u001b[0;31m                     input.size(0), hidden_label, hx.size(0)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input batch size 6 doesn't match hidden[0] batch size 1"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(SENTECE_LEN):\n",
    "    hx, cx = cell(sentence[i], (hx, cx))\n",
    "    output.append(hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTM Layer\n",
    "\n",
    "Args:\n",
    "    - input_size: The number of expected features in the input `x`\n",
    "    - hidden_size: The number of features in the hidden state `h`\n",
    "    - num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
    "        would mean stacking two LSTMs together to form a `stacked LSTM`,\n",
    "        with the second LSTM taking in outputs of the first LSTM and\n",
    "        computing the final results. Default: 1\n",
    "    - bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
    "        Default: ``True``\n",
    "    - batch_first: If ``True``, then the input and output tensors are provided\n",
    "        as (batch, seq, feature). Default: ``False``\n",
    "    - dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
    "        LSTM layer except the last layer, with dropout probability equal to\n",
    "        :attr:`dropout`. Default: 0\n",
    "    - bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``\n",
    "\n",
    "\n",
    "Inputs: input, (h_0, c_0)\n",
    "    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
    "      of the input sequence.\n",
    "      The input can also be a packed variable length sequence.\n",
    "      See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
    "      :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
    "    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "    - **c_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the initial cell state for each element in the batch.\n",
    "\n",
    "      If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n",
    "\n",
    "\n",
    "Outputs: output, (h_n, c_n)\n",
    "    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
    "      containing the output features `(h_t)` from the last layer of the LSTM,\n",
    "      for each `t`. If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n",
    "      given as the input, the output will also be a packed sequence.\n",
    "\n",
    "      For the unpacked case, the directions can be separated\n",
    "      using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
    "      with forward and backward being direction `0` and `1` respectively.\n",
    "      Similarly, the directions can be separated in the packed case.\n",
    "    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the hidden state for `t = seq_len`.\n",
    "\n",
    "      Like *output*, the layers can be separated using\n",
    "      ``h_n.view(num_layers, num_directions, batch, hidden_size)`` and similarly for *c_n*.\n",
    "    - **c_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the cell state for `t = seq_len`.\n",
    "\n",
    "Attributes:\n",
    "    - weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n",
    "        `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n",
    "        Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`\n",
    "    - weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n",
    "        `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`\n",
    "    - bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n",
    "        `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`\n",
    "    - bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n",
    "        `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.LSTM(input_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
